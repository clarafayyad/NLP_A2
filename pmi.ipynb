{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41102fab-7838-4f14-abd7-df2cc22c2192",
   "metadata": {},
   "source": [
    "authors: Julianna Cisewska, Clara Fayyad, Jagoda Hanuszewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a700b2-9725-4200-9749-1de2e7abdca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5086a884-89ac-4011-af6e-27abc1868068",
   "metadata": {},
   "source": [
    "## Bonus question: PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157608d9-3e04-40d5-941d-281b110e667f",
   "metadata": {},
   "source": [
    "In statistical NLP, we frequently make independence assumptions about relevant events which are not actually correct in reality. We are asking you to test the independence assumptions of unigram language models. Pointwise mutual information (PMI), is a measure of statistical dependence of the events \n",
    "Xt = w1 and Xt+1 = w2; \n",
    "C(w) is the absolute frequency and N is the size of the corpus. \n",
    "If the probability of the next word in the corpus being w2 is unaffected by the probability of the previous word being w1, then pmi(w1, w2) = 0; otherwise the PMI is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa2340-1ad0-46c2-a37a-d3dd315568f1",
   "metadata": {},
   "source": [
    "### Step 1. Calculate the PMI for all successive pairs (w1, w2) of words in the Brown corpus. \n",
    "Task: *Words (not word pairs!) that occur in the corpus less than 10 times should be ignored. List the 20 word pairs with the highest PMI value and the 20 word pairs with the lowest PMI value.*  \n",
    "Our answer: We use brown corpus for this assignment. To calculate the PMI scores of the brown corpus we followed this tutorial: https://www.listendata.com/2022/06/pointwise-mutual-information-pmi.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322b5e00-097b-4856-b23a-7120450871db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/jago/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downloads (do only once :))\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "534a2162-cefd-464f-8e10-764b9dffc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 Tokenisation\n",
    "tokens = brown.words()\n",
    "words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "#step 2 Filter out words with less than 10 occurences\n",
    "frequent_words = {word for word, freq in freq_dist.items() if freq >= 10}\n",
    "\n",
    "#step 3 Co-occurence matrix\n",
    "def coocur_matrix(words):\n",
    "    window_size = 2\n",
    "    cooc_matrix = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        word_i = words[i]\n",
    "        if word_i not in frequent_words:\n",
    "            continue\n",
    "        for j in range(max(0, i - window_size), min(len(words), i + window_size + 1)):\n",
    "            if i == j:\n",
    "                continue\n",
    "            word_j = words[j]\n",
    "            if word_j in frequent_words:\n",
    "                cooc_matrix[word_i][word_j] += 1\n",
    "\n",
    "    #step 3.5 Convert matrix to DataFrame\n",
    "    df = pd.DataFrame.from_dict(cooc_matrix, orient='index').fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "#step 4 Compute PMI score\n",
    "def pmi(word1, word2, df):\n",
    "    total_coocs = df.values.sum()\n",
    "\n",
    "    #get frequencies, if word not present = 0\n",
    "    cooc = df.at[word1, word2] if word1 in df.index and word2 in df.columns else 0\n",
    "    freq_word1 = df.loc[word1].sum() if word1 in df.index else 0\n",
    "    freq_word2 = df[word2].sum() if word2 in df.columns else 0\n",
    "\n",
    "    #to avoid division by zero\n",
    "    if cooc == 0 or freq_word1 == 0 or freq_word2 == 0:\n",
    "        return 0\n",
    "\n",
    "    #count probabilities\n",
    "    p_xy = cooc / total_coocs\n",
    "    p_x = freq_word1 / total_coocs\n",
    "    p_y = freq_word2 / total_coocs\n",
    "\n",
    "    return np.log2(p_xy / (p_x * p_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed94da17-dd2d-4b8d-bcc3-7886b8f2903f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMI('government', 'tax'): 1.4686155845745006\n"
     ]
    }
   ],
   "source": [
    "#check if the functions work well\n",
    "df = coocur_matrix(words)\n",
    "print(\"PMI('government', 'tax'):\", pmi('government', 'tax', df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba7f0ed2-9365-4b2f-b69b-915758e71f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that computes all PMI scores for our df\n",
    "#WARNING: this cell takes a lot of time (uses coocurence matrix of >8000x8000 entries)\n",
    "def compute_all_pmi(df):\n",
    "    total_coocs = df.values.sum()\n",
    "    pmi_scores = []\n",
    "\n",
    "    for word1 in df.index:\n",
    "        for word2 in df.columns:\n",
    "            cooc = df.at[word1, word2]\n",
    "            if cooc == 0:\n",
    "                continue  # skip zero co-occurrence\n",
    "\n",
    "            freq_word1 = df.loc[word1].sum()\n",
    "            freq_word2 = df[word2].sum()\n",
    "\n",
    "            p_xy = cooc / total_coocs\n",
    "            p_x = freq_word1 / total_coocs\n",
    "            p_y = freq_word2 / total_coocs\n",
    "\n",
    "            pmi_val = np.log2(p_xy / (p_x * p_y))\n",
    "            pmi_scores.append(((word1, word2), pmi_val))\n",
    "\n",
    "    return pmi_scores\n",
    "\n",
    "#compute and sort the scores\n",
    "pmi_scores = compute_all_pmi(df)\n",
    "pmi_sorted = sorted(pmi_scores, key=lambda x: x[1], reverse=True)  # highest first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d99bb822-65b2-4128-aecf-ab1172eecc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 word pairs with highest PMI:\n",
      "('tents', 'tents'): 15.2477\n",
      "('hong', 'kong'): 14.3740\n",
      "('kong', 'hong'): 14.3740\n",
      "('cellulose', 'cellulose'): 13.8781\n",
      "('lao', 'pathet'): 13.8375\n",
      "('pathet', 'lao'): 13.8375\n",
      "('viet', 'nam'): 13.7366\n",
      "('nam', 'viet'): 13.7366\n",
      "('simms', 'purdew'): 13.7158\n",
      "('purdew', 'simms'): 13.7158\n",
      "('wtv', 'antigen'): 13.7129\n",
      "('antigen', 'wtv'): 13.7129\n",
      "('el', 'paso'): 13.6271\n",
      "('paso', 'el'): 13.6271\n",
      "('tribune', 'herald'): 13.5217\n",
      "('herald', 'tribune'): 13.5217\n",
      "('lo', 'shu'): 13.2723\n",
      "('shu', 'lo'): 13.2723\n",
      "('non', 'non'): 13.2619\n",
      "('puerto', 'rico'): 13.2043\n"
     ]
    }
   ],
   "source": [
    "#top 20 word pairs with the highest PMI value\n",
    "print(\"\\nTop 20 word pairs with highest PMI:\")\n",
    "for pair, score in pmi_sorted[:20]:\n",
    "    print(f\"{pair}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "920b6848-bcab-4100-a1ed-f15dd3ef4cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bottom 20 word pairs with lowest non-zero PMI:\n",
      "('can', 'had'): -5.2432\n",
      "('should', 'is'): -5.2487\n",
      "('is', 'should'): -5.2487\n",
      "('be', 'be'): -5.4462\n",
      "('of', 'turned'): -5.5623\n",
      "('turned', 'of'): -5.5623\n",
      "('been', 'is'): -5.7016\n",
      "('is', 'been'): -5.7016\n",
      "('was', 'are'): -5.8488\n",
      "('are', 'was'): -5.8488\n",
      "('is', 'were'): -6.0521\n",
      "('were', 'is'): -6.0521\n",
      "('been', 'be'): -6.0648\n",
      "('be', 'been'): -6.0648\n",
      "('is', 'could'): -6.0907\n",
      "('could', 'is'): -6.0907\n",
      "('had', 'are'): -6.5085\n",
      "('are', 'had'): -6.5085\n",
      "('had', 'is'): -6.7364\n",
      "('is', 'had'): -6.7364\n"
     ]
    }
   ],
   "source": [
    "#the 20 word pairs with the lowest PMI value\n",
    "print(\"\\nBottom 20 word pairs with lowest non-zero PMI:\")\n",
    "for pair, score in pmi_sorted[-20:]:\n",
    "    print(f\"{pair}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6768b42-2ff4-49a3-b3f8-2ae4d747718c",
   "metadata": {},
   "source": [
    "Note for the negative scores from the tutorial:\n",
    "```Negative PMI means words are co-occurring less than we expect by chance.```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567cce9-9092-4e39-93fd-dc87ccc83451",
   "metadata": {},
   "source": [
    "### Step 2. Discuss the validity of the independence assumption for unigram models. \n",
    "Task: *Give 2-3 examples from your results to support your ideas.*  \n",
    "**For the solution, see the report.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab5419e-fef6-4254-a052-2d6acdbc430a",
   "metadata": {},
   "source": [
    "### Step 3. Extend step 1 by researching and implementing both PMI and positive pointwise mutual information (PPMI). \n",
    "Task: *Do so on the entire Brown corpus and brown100. Document and submit your code with observations as comments in the same file as step 1.*  \n",
    "Our answer: For understanding the difference between PPMI and PMI we followed this source https://towardsmachinelearning.org/positive-point-wise-mutual-information-ppmi/ and the same tutorial from the Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150184a-6d74-4552-b241-2cf024a59f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e41e10d-7922-4cde-8bf5-ae73f284dea1",
   "metadata": {},
   "source": [
    "### Step 4. How does PPMI differ from PMI?\n",
    "Task: *Both generally and given specific examples from your results?*  \n",
    "**For the solution, see the report.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
